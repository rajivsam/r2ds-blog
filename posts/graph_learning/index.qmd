---
title: "Unsupervised Learning and Graphs"
author: "Rajiv Sambasivan"
date: last-modified
categories: [news, code, analysis]
image: "graph.png"
bibliography: references.bib
citation:
  url: https://rajivsam.github.io/r2ds-blog/posts/graph_learning 
---
::: {style="text-align: justify"}
## Unsupervised Learning and Graphs
Graph-based problems often fall into one of the following categories:

1. **Prediction with Partial Graphs:** Given a graph that is partially observed, can you predict node property values on unobserved nodes? Can you predict if an unobserved pair of nodes are connected by an edge?

2. **Graph Structure Inference from Node Signals:** Given values or signals assigned to the nodes, can you infer the underlying graph structure? Here, you lack explicit examples of which nodes should be connected, and the challenge is to determine the connections that best explain the observed node signals.

So if you are like me, you are probably thinking that the second example is a candidate for unsupervised learning and I agree. The problem is that you will run into the problem of selecting a threshold value in your learning task. For example, if you choose to cluster nodes using the notion of similarity or distance, then you need to decide that nodes that are closer or more similar than a threshold value are connected. If you have access to domain knowledge or have a good understanding of the problem you are trying to solve, you can come up with reasonable solutions.

What I wanted to talk about in this post is that you can appeal to Graph Signal Processing for help too.
I am not going into the details, rather, I am going to discuss the intuition and the motivation and point you to some references if you want to find out more. The ideas are from this paper [@dong2019learning]. There is an excellent youtube talk that covers the ideas in this paper [@dong_youtube].

Given observations on the nodes of a graph the paper (and talk) discuss three approaches to learning the associated graph. 

1. By choosing how smooth you want your signal to be. When a signal is observed on the nodes of a graph, the eigen decomposition of the laplacian of the graph tells us how smoothly the signal will vary over the nodes of the graph. We can control the smoothness with a regularization term, i.e., you pick a regularization term that makes the signal smooth enough for your particular problem. This is your choice as a modeler. **Learning the graph laplacian translates to learning the graph**. The graphical lasso [@friedman2008sparse] is used to learn the laplacian.
2. By selecting how a signal should diffuse through a graph. Diffusion on graphs, associated kernels is an extensive topic. If the diffusion perspective is right for your application, for example in disease modeling, then this might appeal to you.
3. By assuming a causal structure. If you have a causal model associated with the variables of the graph, you can use this approach to learning the graph.

The olist geographical sales by cities in Sau Paulo for 2017 is a good candidate to explore the first approach. So I might try that.



:::